{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import undetected_chromedriver as uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Chrome options for undetected ChromeDriver\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"start-maximized\")  # Start browser in maximized mode\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Bypass bot detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize undetected ChromeDriver\n",
    "upwork_ai = uc.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job links from CSV file\n",
    "df_jobs = pd.read_csv(\"artificial_intelligence_Jobs_Links.csv\")\n",
    "rows, cols = df_jobs.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert job links column to a list\n",
    "link_list = df_jobs[\"Link\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set page load timeout\n",
    "upwork_ai.set_page_load_timeout(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage lists\n",
    "scraped_data = []\n",
    "error_scrapped = 0\n",
    "count = 0\n",
    "scrapped_links = 0\n",
    "# Loop through each job link\n",
    "for url in link_list:\n",
    "    upwork_ai.get(url)  # Open the job page\n",
    "    time.sleep(20)  # Allow page to load completely\n",
    "    \n",
    "    try:\n",
    "        # Extract job title\n",
    "        title = [t.text for t in upwork_ai.find_elements(By.XPATH, '//h4[@class=\"m-0\"]')]\n",
    "        \n",
    "        # Extract job location\n",
    "        location = [l.text for l in upwork_ai.find_elements(By.XPATH, '//span[@class=\"text-light-on-muted\" and @data-v-371e7192=\"\"]')]\n",
    "        \n",
    "        # Extract job description\n",
    "        description = [d.text for d in upwork_ai.find_elements(By.XPATH, '//p[@class=\"text-body-sm\" and @data-v-7304a83e=\"\"]')]\n",
    "        \n",
    "        # Extract fixed price (if applicable)\n",
    "        fixed_price = [p.text for p in upwork_ai.find_elements(By.XPATH, '//strong[@data-v-175eba53]')]\n",
    "        \n",
    "        # Extract budget details (min and max budget)\n",
    "        budget_elements = upwork_ai.find_elements(By.XPATH, '//div[@data-test=\"BudgetAmount\"]/p/strong')\n",
    "        budget_values = [b.text.strip() for b in budget_elements if b.text.strip()]\n",
    "        min_budget = budget_values[0] if len(budget_values) > 0 else None\n",
    "        max_budget = budget_values[1] if len(budget_values) > 1 else None\n",
    "        \n",
    "        # Extract job application details (proposals, interviews, invites sent, unanswered invites)\n",
    "        proposals = [p.text for p in upwork_ai.find_elements(By.XPATH, '//li[@class=\"ca-item\"]//span[contains(text(), \"Proposals:\")]/following-sibling::span[@class=\"value\"]')]\n",
    "        interviewing = [i.text for i in upwork_ai.find_elements(By.XPATH, '//li[@class=\"ca-item\"]//span[contains(text(), \"Interviewing:\")]/following-sibling::div')]\n",
    "        invites_sent = [i.text for i in upwork_ai.find_elements(By.XPATH, '//li[@class=\"ca-item\"]//span[contains(text(), \"Invites sent:\")]/following-sibling::div')]\n",
    "        unanswered_invites = [u.text for u in upwork_ai.find_elements(By.XPATH, '//li[@class=\"ca-item\"]//span[contains(text(), \"Unanswered invites:\")]/following-sibling::div')]\n",
    "        \n",
    "        # Extract client details (total spend, location, hires, active jobs)\n",
    "        client_total_spent = [c.text for c in upwork_ai.find_elements(By.XPATH, '//strong[@data-qa=\"client-spend\"]/span')]\n",
    "        client_location = [l.text.strip() for l in upwork_ai.find_elements(By.XPATH, '//li[@data-qa=\"client-location\"]/strong')]\n",
    "        \n",
    "        # Extract hires and active job details\n",
    "        hires_elements = upwork_ai.find_elements(By.XPATH, '//div[@data-qa=\"client-hires\"]')\n",
    "        hires_text = hires_elements[0].text.strip() if hires_elements else None\n",
    "        hires, active = None, None\n",
    "        if hires_text:\n",
    "            numbers = re.findall(r'\\d+', hires_text)\n",
    "            hires = numbers[0] if len(numbers) > 0 else None\n",
    "            active = numbers[1] if len(numbers) > 1 else None  \n",
    "        \n",
    "        # Extract experience level (Entry, Intermediate, Expert)\n",
    "        experience_levels = [\"Expert\", \"Intermediate\", \"Entry\"]\n",
    "        experience_level = None\n",
    "        for level in experience_levels:\n",
    "            exp_element = upwork_ai.find_elements(By.XPATH, f'//strong[contains(text(), \"{level}\")]')\n",
    "            if exp_element:\n",
    "                experience_level = level\n",
    "                break\n",
    "        \n",
    "        # Extract skills required\n",
    "        skill_elements = upwork_ai.find_elements(By.XPATH, '//span[contains(@class, \"air3-badge-highlight\")]')\n",
    "        skills = list(set([skill.text.strip() for skill in skill_elements if skill.text.strip()]))\n",
    "        \n",
    "        # Extract job type (Hourly or Fixed-price)\n",
    "        job_type_element = upwork_ai.find_elements(By.XPATH, '//div[@class=\"description\"][text()=\"Hourly\" or text()=\"Fixed-price\"]')\n",
    "        job_type = job_type_element[0].text if job_type_element else None\n",
    "        \n",
    "        # Extract duration and work hours (for hourly jobs)\n",
    "        duration = None\n",
    "        work_hours = None\n",
    "        if job_type == \"Hourly\":\n",
    "            duration_element = upwork_ai.find_elements(By.XPATH, '//strong[contains(text(), \"month\")]')\n",
    "            work_hours_element = upwork_ai.find_elements(By.XPATH, '//strong[contains(text(), \"hrs/week\")]')\n",
    "            duration = duration_element[0].text if duration_element else None\n",
    "            work_hours = work_hours_element[0].text if work_hours_element else None\n",
    "        \n",
    "        # Store extracted data\n",
    "        scraped_data.append({\n",
    "            \"title\": title[0] if title else None,\n",
    "            \"url\": url,\n",
    "            \"job_type\": job_type,\n",
    "            \"location\": location[0] if location else None,\n",
    "            \"description\": description[0] if description else None,\n",
    "            \"min_budget\": min_budget,\n",
    "            \"max_budget\": max_budget,\n",
    "            \"fixed_price\": fixed_price if fixed_price else None,\n",
    "            \"experience_level\": experience_level,\n",
    "            \"skills\": skills,\n",
    "            \"duration\": duration,\n",
    "            \"work_hours\": work_hours,\n",
    "            \"proposals\": proposals[0] if proposals else None,\n",
    "            \"interviewing\": interviewing[0] if interviewing else None,\n",
    "            \"invites_sent\": invites_sent[0] if invites_sent else None,\n",
    "            \"unanswered_invites\": unanswered_invites[0] if unanswered_invites else None,\n",
    "            \"client_total_spent\": client_total_spent[0] if client_total_spent else None,\n",
    "            \"client_location\": client_location[0] if client_location else None,\n",
    "            \"active\": active,\n",
    "            \"hires\": hires\n",
    "        })\n",
    "        \n",
    "        scrapped_links += 1\n",
    "        print(f\"Scraped Links: {scrapped_links}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_scrapped += 1\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        print(f\"Not Scrapped: {error_scrapped}\")\n",
    "    \n",
    "    count += 1\n",
    "    print(f\"URL Finished: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scraped data into a DataFrame and save as CSV\n",
    "df_scrapped_jobs = pd.DataFrame(scraped_data)\n",
    "df_scrapped_jobs.to_csv(\"scrapped_AI_jobs_version1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser session\n",
    "upwork_ai.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame info\n",
    "df_scrapped_jobs.info()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
