# -*- coding: utf-8 -*-
"""Data_Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X-bluL_UnVVPCBcQQefXQmjTJJ-SXSew

Import necessary libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import re
import matplotlib.pyplot as plt
import ast
from collections import Counter

"""Load dataset"""

jobs_file = "real_dataset_android.csv"
df = pd.read_csv(jobs_file)
pd.set_option('display.max_columns', None)

"""# Data Exploration

Display basic information about the dataset
"""

df.head()  # Preview first few rows

df.info()  # Overview of dataset structure

df.isna().sum() # Count of missing values per column
# df.isnull().sum()

df['client_location'].unique()

df.work_hours.value_counts()

df.duration.value_counts()

df.proposals.value_counts()

df.experience_level.value_counts()

df.job_type.value_counts()

df.location.value_counts()

"""# Data Preprocessing"""

print(f'Number of Records: {df.shape[0]}')
df = df.dropna(subset='title')
df = df.drop_duplicates(subset='title', keep='first')
print(f'Number of Records (after dropping NaNs and duplicates): {df.shape[0]}')

"""Drop unnecessary columns"""

df.drop(columns=['location', 'client_industry', 'client_type'], inplace=True)

"""Drop duplicates and clean missing values"""

df.dropna(subset=["title"], inplace=True)  # Remove rows where title is missing
df.drop_duplicates(subset=["title"], inplace=True)  # Remove duplicate job titles
df = df.dropna(subset=['min_budget', 'client_location', 'proposals','interviewing', 'invites_sent', 'unanswered_invites']).reset_index(drop=True)

"""Filter out inconsistent job records"""

df = df[~((df['work_hours'].isna()) &
          ~(df['max_budget'].isna() & df['duration'].isna() & df['work_hours'].isna() &
            (df['job_type'] == 'Fixed-price')))]

"""Drop rows where all specified columns have missing values"""

df.dropna(subset=['min_budget', 'fixed_price'], how='all', inplace=True)
df.dropna(subset=['proposals', 'interviewing', 'invites_sent', 'unanswered_invites'], how='all', inplace=True)
df.dropna(subset=['interviewing'], inplace=True)

"""Convert budget columns from string to numeric"""

df['min_budget'] = df['min_budget'].replace('[\$,]', '', regex=True).astype(float)
df['max_budget'] = df['max_budget'].replace('[\$,]', '', regex=True).astype(float)

"""Function to calculate average budget"""

def calculate_average(row):
    """
    Calculates the average budget for a job post.

    Args:
        row (pd.Series): A row of the DataFrame containing min and max budgets.

    Returns:
        float: The average budget if max_budget exists; otherwise, min_budget.
    """
    if pd.notna(row['max_budget']):
        return (row['min_budget'] + row['max_budget']) / 2
    return row['min_budget']

# Apply the function to compute the average budget
df['average_budget'] = df.apply(calculate_average, axis=1)

df['duration'] = df.apply(lambda data: 'Not Defined' if pd.isna(data['duration']) and data['job_type'] == 'Fixed-price' else data['duration'], axis=1)
df['work_hours'] = df.apply(lambda data: 'Flexible' if pd.isna(data['work_hours']) and data['job_type'] == 'Fixed-price' else data['work_hours'], axis=1)

"""Mapping categorical values to numerical representations"""

work_hours_map = {
    'Less than 30 hrs/week': 'less_than_30',
    'More than 30 hrs/week': 'more_than_30',
    'Flexible': 'flexible'
}

duration_map = {
    'Not Defined': 0,
    '< 1 month': 1,
    '1-3 months': 2,
    '3-6 months': 3,
    '6+ months': 4
}

df['duration'] = df['duration'].map(duration_map)

proposal_mapping = {
    'Less than 5': 1,
    '5 to 10': 2,
    '10 to 15': 3,
    '15 to 20': 4,
    '20 to 50': 5,
    '50+': 6
}
df['proposals'] = df['proposals'].map(proposal_mapping)

experience_mapping = {
    'Entry': 1,
    'Intermediate': 2,
    'Expert': 3
}
df['experience_level'] = df['experience_level'].map(experience_mapping)

job_type_mapping = {
    'Hourly': 0,
    'Fixed-price': 1
}
df['job_type'] = df['job_type'].map(job_type_mapping)

country_map = {
    'USA': 'United States', 'GBR': 'United Kingdom', 'CAN': 'Canada', 'TUN': 'Tunisia',
    'ITA': 'Italy', 'FRA': 'France', 'IND': 'India', 'AUS': 'Australia', 'ARE': 'United Arab Emirates',
    'IDN': 'Indonesia', 'SGP': 'Singapore', 'PAK': 'Pakistan', 'PRT': 'Portugal', 'MEX': 'Mexico',
    'GRC': 'Greece', 'BEL': 'Belgium', 'COL': 'Colombia', 'ISR': 'Israel', 'MKD': 'North Macedonia',
    'NGA': 'Nigeria', 'ZAF': 'South Africa', 'MLT': 'Malta', 'LKA': 'Sri Lanka', 'KWT': 'Kuwait',
    'IRL': 'Ireland', 'DEU': 'Germany', 'JOR': 'Jordan', 'MYS': 'Malaysia', 'CHE': 'Switzerland',
    'CYP': 'Cyprus', 'KOR': 'South Korea', 'BRA': 'Brazil', 'SRB': 'Serbia', 'SWE': 'Sweden',
    'PRI': 'Puerto Rico', 'MKD': 'North Macedonia', 'BHR': 'Bahrain', 'TUR': 'Turkey',
    'BOL': 'Bolivia', 'PHL': 'Philippines', 'LUX': 'Luxembourg', 'NEP': 'Nepal', 'ARG': 'Argentina'
}

df['client_location'] = df['client_location'].replace(country_map)

"""One-hot encoding for work hours category"""

df = pd.get_dummies(df, columns=['work_hours'], prefix='work_hours', dtype='int')

"""Function to convert money values (K, M notation) to numerical format"""

def convert_money(value):
    """
    Converts monetary values from string format with 'K' or 'M' to float.

    Args:
        value (str): The monetary value as a string.

    Returns:
        float: The converted monetary value.
    """
    if pd.isna(value):
        return None
    value = value.replace("$", "")
    if "K" in value:
        return float(value.replace("K", "")) * 1_000
    elif "M" in value:
        return float(value.replace("M", "")) * 1_000_000
    return float(value)

# Apply money conversion function to the client spending column
df['client_total_spent'] = df['client_total_spent'].apply(convert_money)

# Drop unnecessary budget columns
df.drop(columns=['min_budget', 'max_budget', 'fixed_price'], inplace=True)

"""Plot histogram for client_total_spent"""

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.histplot(df["client_total_spent"], bins=30, kde=True, color='blue')
plt.title("Histogram of client_total_spent")

plt.show()

log_client_total_spent = np.log(df['client_total_spent'])

"""Plot histogram for log_client_total_spent"""

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.histplot(log_client_total_spent, bins=30, kde=True, color='blue')
plt.title("Histogram of log_client_total_spent")

plt.show()

log_client_total_spent = log_client_total_spent.fillna(log_client_total_spent.mean())
df['reversed_log_client_total_spent'] = np.exp(log_client_total_spent)

"""Plot histogram for reversed_log_client_total_spent"""

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.histplot(df["reversed_log_client_total_spent"], bins=30, kde=True, color='blue')
plt.title("Histogram of reversed_log_client_total_spent")

plt.show()

"""Pick 600 Records from Dataset"""

null_rows = df[(df['hires'].isnull()) & (df['active'].isnull())]
rows_to_drop = df.shape[0] - 600
df = df.drop(null_rows.head(rows_to_drop).index).reset_index(drop=True)

"""Preprocess Skills Column"""

df['skills'] = df['skills'].apply(ast.literal_eval)

skill_counts = Counter(skill for skills in df['skills'] for skill in skills)

skill_counts_df = pd.DataFrame(skill_counts.items(), columns=['Skill', 'Count']).sort_values(by='Count', ascending=False)

skill_counts_df.head()

skill_counts_df.to_csv('skill_count.csv', index=False)

"""Insert a new column for job category (track)"""

track_name = "android_developer"
df.insert(0, "track_name", track_name)

"""Final Check of Dataset"""

df.head()

df.info(verbose=True)

df.isnull().sum()

"""Save CSV File"""

track = 'AD'
df.to_csv(f'preprocessed_{track}.csv', index=False)

df.shape

"""# Trial of Combining DFs"""

df1 = pd.read_csv("D:\DEP-Project-main\Android_Developer_Scrapped_Data.csv")
df2 = pd.read_csv("D:\DEP-Project-main\Artificial_Intelligence_Scrapped_Data.csv")
df3 = pd.read_csv("Data_Analyst_Scrapped_Data.csv")
df4 = pd.read_csv("D:\DEP-Project-main\Javascript_Developer_Scrapped_Data.csv")

df1.info()

df1 = df1.drop(columns=['client_industry','client_type'])

df1.info()

df2.info()

df2 = df2.drop(columns=['location'])

track_name = "artificial_intelligence"
df2.insert(0, "track_name", track_name)

df2.info()

df3.info()

df3 = df3.drop(columns=df3.columns[0])

df3.info()

df4.info()

df4 = df4.drop(columns=['client_industry','client_type'])

track_name = "javascript_developer"
df4.insert(0, "track_name", "javascript_developer")

df4.info()

df4 = df4.drop(columns=['location'])

df_combined = pd.concat([df1, df2,df3,df4], ignore_index=True)

df_combined.info()

df_combined.head()

df_combined.tail()

df_combined.shape

df_combined.to_csv("Upwork_Scrapped_Dataset.csv")

